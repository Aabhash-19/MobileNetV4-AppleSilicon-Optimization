{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b775cb",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7333db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92561b10",
   "metadata": {},
   "source": [
    "### Checking GPU Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10ce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "MPS built: True\n",
      "Device count: 1\n",
      "✅ Using MPS (GPU acceleration)\n",
      "Current device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", torch.backends.mps.is_built())\n",
    "print(\"Device count:\", torch.mps.device_count())\n",
    "\n",
    "# Setting device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using MPS (GPU acceleration)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"❌ Using CPU only\")\n",
    "\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee19772",
   "metadata": {},
   "source": [
    "### Convolution Expansion and Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9982967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expansion_ratio=6):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        hidden_dim = int(in_channels * expansion_ratio)\n",
    "        self.use_residual = stride == 1 and in_channels == out_channels\n",
    "        \n",
    "        layers = []\n",
    "        # Pointwise convolution for expansion\n",
    "        if expansion_ratio != 1:\n",
    "            layers.append(nn.Conv2d(in_channels, hidden_dim, 1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "            layers.append(nn.ReLU6(inplace=True))\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        layers.append(nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, \n",
    "                               groups=hidden_dim, bias=False))\n",
    "        layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "        layers.append(nn.ReLU6(inplace=True))\n",
    "        \n",
    "        # Pointwise convolution for projection\n",
    "        layers.append(nn.Conv2d(hidden_dim, out_channels, 1, bias=False))\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        self.conv = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.use_residual:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa9eb5",
   "metadata": {},
   "source": [
    "### Building Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc78786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV4Base(nn.Module):\n",
    "    def __init__(self, num_classes=10, width_mult=1.0):\n",
    "        super(MobileNetV4Base, self).__init__()\n",
    "        \n",
    "        # Initial convolution layer\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        \n",
    "        # MobileNetV4 configuration\n",
    "        inverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        \n",
    "        # Building first layer\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * max(1.0, width_mult))\n",
    "        \n",
    "        features = [nn.Sequential(\n",
    "            nn.Conv2d(3, input_channel, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(input_channel),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )]\n",
    "        \n",
    "        # Building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(InvertedResidual(input_channel, output_channel, \n",
    "                                               stride, t))\n",
    "                input_channel = output_channel\n",
    "        \n",
    "        # Building last several layers\n",
    "        features.append(nn.Sequential(\n",
    "            nn.Conv2d(input_channel, self.last_channel, 1, bias=False),\n",
    "            nn.BatchNorm2d(self.last_channel),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ))\n",
    "        \n",
    "        self.features = nn.Sequential(*features)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Weight initialization\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f7255",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe53c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, device, epochs=10, lr=0.01):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    # Adding timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time.time()  # Start time for this epoch\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Move data to GPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch: {epoch+1:2d}/{epochs} | '\n",
    "                      f'Batch: {batch_idx:4d}/{len(train_loader)} | '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        # Evaluating on test set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                # Move data to GPU\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "        # Printing epoch time\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        total_time = time.time() - start_time\n",
    "        print(f'Epoch {epoch+1:2d}/{epochs} | '\n",
    "              f'Loss: {avg_loss:.4f} | '\n",
    "              f'Accuracy: {accuracy:.2f}% | '\n",
    "              f'Epoch Time: {epoch_time:.1f}s | '\n",
    "              f'Total Time: {total_time/60:.1f}m')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return train_losses, test_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2c68b",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97014a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, \n",
    "                                    download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                   download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                             shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                            shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3b9ca",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e786d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ USING MPS (APPLE SILICON GPU ACCELERATION)\n",
      "Device: mps\n",
      "\n",
      "Training Base MobileNetV4 Model...\n",
      "GPU Memory allocated: 34.7490234375 MB\n",
      "Epoch:  1/20 | Batch:    0/391 | Loss: 2.3047\n",
      "Epoch:  1/20 | Batch:  100/391 | Loss: 1.9696\n",
      "Epoch:  1/20 | Batch:  200/391 | Loss: 1.7546\n",
      "Epoch:  1/20 | Batch:  300/391 | Loss: 1.6737\n",
      "Epoch  1/20 | Loss: 1.9147 | Accuracy: 40.36% | Epoch Time: 50.0s | Total Time: 0.8m\n",
      "Epoch:  2/20 | Batch:    0/391 | Loss: 1.5431\n",
      "Epoch:  2/20 | Batch:  100/391 | Loss: 1.5763\n",
      "Epoch:  2/20 | Batch:  200/391 | Loss: 1.5947\n",
      "Epoch:  2/20 | Batch:  300/391 | Loss: 1.5678\n",
      "Epoch  2/20 | Loss: 1.5275 | Accuracy: 49.24% | Epoch Time: 42.0s | Total Time: 1.5m\n",
      "Epoch:  3/20 | Batch:    0/391 | Loss: 1.4828\n",
      "Epoch:  3/20 | Batch:  100/391 | Loss: 1.3814\n",
      "Epoch:  3/20 | Batch:  200/391 | Loss: 1.4382\n",
      "Epoch:  3/20 | Batch:  300/391 | Loss: 1.2817\n",
      "Epoch  3/20 | Loss: 1.3474 | Accuracy: 53.77% | Epoch Time: 42.5s | Total Time: 2.2m\n",
      "Epoch:  4/20 | Batch:    0/391 | Loss: 1.2185\n",
      "Epoch:  4/20 | Batch:  100/391 | Loss: 1.2639\n",
      "Epoch:  4/20 | Batch:  200/391 | Loss: 1.2203\n",
      "Epoch:  4/20 | Batch:  300/391 | Loss: 1.1419\n",
      "Epoch  4/20 | Loss: 1.2225 | Accuracy: 55.94% | Epoch Time: 42.3s | Total Time: 2.9m\n",
      "Epoch:  5/20 | Batch:    0/391 | Loss: 1.1192\n",
      "Epoch:  5/20 | Batch:  100/391 | Loss: 1.1103\n",
      "Epoch:  5/20 | Batch:  200/391 | Loss: 1.1914\n",
      "Epoch:  5/20 | Batch:  300/391 | Loss: 0.9907\n",
      "Epoch  5/20 | Loss: 1.1151 | Accuracy: 58.08% | Epoch Time: 42.4s | Total Time: 3.7m\n",
      "Epoch:  6/20 | Batch:    0/391 | Loss: 1.0256\n",
      "Epoch:  6/20 | Batch:  100/391 | Loss: 0.9263\n",
      "Epoch:  6/20 | Batch:  200/391 | Loss: 1.2433\n",
      "Epoch:  6/20 | Batch:  300/391 | Loss: 0.9876\n",
      "Epoch  6/20 | Loss: 1.0238 | Accuracy: 62.06% | Epoch Time: 42.5s | Total Time: 4.4m\n",
      "Epoch:  7/20 | Batch:    0/391 | Loss: 0.9160\n",
      "Epoch:  7/20 | Batch:  100/391 | Loss: 1.0857\n",
      "Epoch:  7/20 | Batch:  200/391 | Loss: 0.9899\n",
      "Epoch:  7/20 | Batch:  300/391 | Loss: 0.8389\n",
      "Epoch  7/20 | Loss: 0.9449 | Accuracy: 63.34% | Epoch Time: 42.6s | Total Time: 5.1m\n",
      "Epoch:  8/20 | Batch:    0/391 | Loss: 0.8258\n",
      "Epoch:  8/20 | Batch:  100/391 | Loss: 0.8972\n",
      "Epoch:  8/20 | Batch:  200/391 | Loss: 0.9812\n",
      "Epoch:  8/20 | Batch:  300/391 | Loss: 0.9760\n",
      "Epoch  8/20 | Loss: 0.8823 | Accuracy: 64.90% | Epoch Time: 43.1s | Total Time: 5.8m\n",
      "Epoch:  9/20 | Batch:    0/391 | Loss: 0.7575\n",
      "Epoch:  9/20 | Batch:  100/391 | Loss: 0.7894\n",
      "Epoch:  9/20 | Batch:  200/391 | Loss: 0.9163\n",
      "Epoch:  9/20 | Batch:  300/391 | Loss: 0.7658\n",
      "Epoch  9/20 | Loss: 0.8244 | Accuracy: 67.47% | Epoch Time: 43.5s | Total Time: 6.5m\n",
      "Epoch: 10/20 | Batch:    0/391 | Loss: 0.7473\n",
      "Epoch: 10/20 | Batch:  100/391 | Loss: 0.7779\n",
      "Epoch: 10/20 | Batch:  200/391 | Loss: 0.8588\n",
      "Epoch: 10/20 | Batch:  300/391 | Loss: 0.6949\n",
      "Epoch 10/20 | Loss: 0.7750 | Accuracy: 67.50% | Epoch Time: 42.6s | Total Time: 7.2m\n",
      "Epoch: 11/20 | Batch:    0/391 | Loss: 0.6262\n",
      "Epoch: 11/20 | Batch:  100/391 | Loss: 0.6044\n",
      "Epoch: 11/20 | Batch:  200/391 | Loss: 0.6175\n",
      "Epoch: 11/20 | Batch:  300/391 | Loss: 0.8165\n",
      "Epoch 11/20 | Loss: 0.7262 | Accuracy: 68.55% | Epoch Time: 42.5s | Total Time: 7.9m\n",
      "Epoch: 12/20 | Batch:    0/391 | Loss: 0.6414\n",
      "Epoch: 12/20 | Batch:  100/391 | Loss: 0.5923\n",
      "Epoch: 12/20 | Batch:  200/391 | Loss: 0.7300\n",
      "Epoch: 12/20 | Batch:  300/391 | Loss: 0.6798\n",
      "Epoch 12/20 | Loss: 0.6866 | Accuracy: 69.25% | Epoch Time: 42.1s | Total Time: 8.6m\n",
      "Epoch: 13/20 | Batch:    0/391 | Loss: 0.7113\n",
      "Epoch: 13/20 | Batch:  100/391 | Loss: 0.8500\n",
      "Epoch: 13/20 | Batch:  200/391 | Loss: 0.6549\n",
      "Epoch: 13/20 | Batch:  300/391 | Loss: 0.7135\n",
      "Epoch 13/20 | Loss: 0.6455 | Accuracy: 69.89% | Epoch Time: 42.4s | Total Time: 9.3m\n",
      "Epoch: 14/20 | Batch:    0/391 | Loss: 0.4381\n",
      "Epoch: 14/20 | Batch:  100/391 | Loss: 0.5011\n",
      "Epoch: 14/20 | Batch:  200/391 | Loss: 0.6192\n",
      "Epoch: 14/20 | Batch:  300/391 | Loss: 0.6429\n",
      "Epoch 14/20 | Loss: 0.6163 | Accuracy: 69.89% | Epoch Time: 42.3s | Total Time: 10.0m\n",
      "Epoch: 15/20 | Batch:    0/391 | Loss: 0.4865\n",
      "Epoch: 15/20 | Batch:  100/391 | Loss: 0.4669\n",
      "Epoch: 15/20 | Batch:  200/391 | Loss: 0.5201\n",
      "Epoch: 15/20 | Batch:  300/391 | Loss: 0.5489\n",
      "Epoch 15/20 | Loss: 0.5741 | Accuracy: 69.85% | Epoch Time: 42.8s | Total Time: 10.8m\n",
      "Epoch: 16/20 | Batch:    0/391 | Loss: 0.4947\n",
      "Epoch: 16/20 | Batch:  100/391 | Loss: 0.4992\n",
      "Epoch: 16/20 | Batch:  200/391 | Loss: 0.4844\n",
      "Epoch: 16/20 | Batch:  300/391 | Loss: 0.7024\n",
      "Epoch 16/20 | Loss: 0.5498 | Accuracy: 69.63% | Epoch Time: 42.5s | Total Time: 11.5m\n",
      "Epoch: 17/20 | Batch:    0/391 | Loss: 0.5187\n",
      "Epoch: 17/20 | Batch:  100/391 | Loss: 0.6559\n",
      "Epoch: 17/20 | Batch:  200/391 | Loss: 0.5527\n",
      "Epoch: 17/20 | Batch:  300/391 | Loss: 0.4452\n",
      "Epoch 17/20 | Loss: 0.5187 | Accuracy: 69.67% | Epoch Time: 42.0s | Total Time: 12.2m\n",
      "Epoch: 18/20 | Batch:    0/391 | Loss: 0.5838\n",
      "Epoch: 18/20 | Batch:  100/391 | Loss: 0.4386\n",
      "Epoch: 18/20 | Batch:  200/391 | Loss: 0.6048\n",
      "Epoch: 18/20 | Batch:  300/391 | Loss: 0.5157\n",
      "Epoch 18/20 | Loss: 0.4968 | Accuracy: 70.31% | Epoch Time: 42.4s | Total Time: 12.9m\n",
      "Epoch: 19/20 | Batch:    0/391 | Loss: 0.3992\n",
      "Epoch: 19/20 | Batch:  100/391 | Loss: 0.5780\n",
      "Epoch: 19/20 | Batch:  200/391 | Loss: 0.5601\n",
      "Epoch: 19/20 | Batch:  300/391 | Loss: 0.4666\n",
      "Epoch 19/20 | Loss: 0.4728 | Accuracy: 70.97% | Epoch Time: 42.3s | Total Time: 13.6m\n",
      "Epoch: 20/20 | Batch:    0/391 | Loss: 0.3508\n",
      "Epoch: 20/20 | Batch:  100/391 | Loss: 0.4258\n",
      "Epoch: 20/20 | Batch:  200/391 | Loss: 0.4948\n",
      "Epoch: 20/20 | Batch:  300/391 | Loss: 0.4949\n",
      "Epoch 20/20 | Loss: 0.4426 | Accuracy: 70.09% | Epoch Time: 42.1s | Total Time: 14.3m\n",
      "Final Test Accuracy (Base): 70.09%\n",
      "Peak GPU Memory usage: 1.2088775634765625 GB\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Setup device with MPS support for Apple Silicon\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"✅ USING MPS (APPLE SILICON GPU ACCELERATION)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"⚠️  USING CPU ONLY (NO GPU ACCELERATION)\")\n",
    "    \n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Preparing data with larger batch size for better GPU utilization\n",
    "    train_loader, test_loader = prepare_data(batch_size=128)  # Increased from 64\n",
    "    \n",
    "    # Creating and train base model\n",
    "    print(\"\\nTraining Base MobileNetV4 Model...\")\n",
    "    base_model = MobileNetV4Base(num_classes=10).to(device)  # Move model to GPU\n",
    "    \n",
    "    # Adding this to monitor GPU memory usage\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"GPU Memory allocated:\", torch.mps.current_allocated_memory() / 1024**2, \"MB\")\n",
    "    \n",
    "    train_losses_base, test_accuracies_base = train_model(\n",
    "        base_model, train_loader, test_loader, device, epochs=20, lr=0.001\n",
    "    )\n",
    "    \n",
    "    print(f\"Final Test Accuracy (Base): {test_accuracies_base[-1]:.2f}%\")\n",
    "    \n",
    "    # Additional GPU info\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"Peak GPU Memory usage:\", torch.mps.driver_allocated_memory() / 1024**3, \"GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
